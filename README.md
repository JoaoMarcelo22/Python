# ğŸ“Œ RepositÃ³rio de Python e Pandas

Este repositÃ³rio contÃ©m scripts e exemplos de manipulaÃ§Ã£o de dados utilizando Python e Pandas. O objetivo Ã© fornecer uma base sÃ³lida para anÃ¡lise de dados, incluindo limpeza, transformaÃ§Ã£o e visualizaÃ§Ã£o.

## ğŸ“‚ Estrutura do RepositÃ³rio

- `notebooks/` â†’ Jupyter Notebooks com exemplos prÃ¡ticos.
- `docs/` â†’ DocumentaÃ§Ã£o e materiais complementares.

## ğŸš€ Tecnologias Utilizadas

- ğŸ **Python** â†’ Linguagem principal.
- ğŸ“Š **Pandas** â†’ ManipulaÃ§Ã£o e anÃ¡lise de dados.
- ğŸ”¢ **NumPy** â†’ Suporte para cÃ¡lculos numÃ©ricos.
- ğŸ“ˆ **Matplotlib & Seaborn** â†’ VisualizaÃ§Ã£o de dados.
- ğŸ›  **Jupyter Notebook** â†’ ExecuÃ§Ã£o interativa dos cÃ³digos.
- ğŸ›  **Google Colab Notebook** â†’ ExecuÃ§Ã£o interativa dos cÃ³digos.

## ğŸ“š ConteÃºdo

### 1ï¸âƒ£ Tratamento de Dados
- Tratamento de valores nulos e duplicados
- TransformaÃ§Ãµes e limpeza de dados
- Merge, Join e Concatenation de DataFrames

### 2ï¸âƒ£ AnÃ¡lise ExploratÃ³ria de Dados
- EstatÃ­sticas descritivas com Pandas
- GrÃ¡ficos com Matplotlib e Seaborn
- AnÃ¡lise exploratÃ³ria de dados (EDA)

### 3ï¸âƒ£ PreparaÃ§Ã£o e Engenharia de Atributos (Feature Engineering)
#### 3.1. PreparaÃ§Ã£o dos dados
- NormalizaÃ§Ã£o / padronizaÃ§Ã£o
- Encoding de variÃ¡veis categÃ³ricas (One-Hot, Label Encoding)
- Tratamento mais refinado de outliers
- Binning de variÃ¡veis numÃ©ricas (quantis, equal-width)
- Balanceamento de classes (SMOTE, undersampling)
#### 3.2. CriaÃ§Ã£o de novas features
- Atributos derivados (mÃ©dias mÃ³veis, diferenÃ§as, razÃµes)
- AgregaÃ§Ãµes por grupos
- Features temporais (mÃªs, dia da semana, sazonalidade)
- InteraÃ§Ãµes entre variÃ¡veis (multiplicaÃ§Ãµes, somas, razÃµes)
#### 3.3. SeleÃ§Ã£o de features
- ANOVA, ChiÂ², Mutual Information
- ImportÃ¢ncia de features (Ã¡rvores)
- PCA, UMAP (reduÃ§Ã£o de dimensionalidade)

### 4ï¸âƒ£ Modelagem (Machine Learning / EstatÃ­stica)
#### 4.1. Escolha dos algoritmos
- RegressÃµes (Linear, Ridge, Lasso)
- ClassificaÃ§Ã£o (XGBoost, Random Forest, Logistic Regression)
- SÃ©ries temporais (Prophet, ARIMA)
- Deep Learning (transformers, CNNs, RNNS)
- Modelos nÃ£o supervisionados (K-Means, DBSCAN, PCA, Isolation Forest.)

### 5ï¸âƒ£ Treinamento do Modelo
- Dividir dados (train, validation, test).
- Treinar modelos com mÃ©tricas adequadas.
- Ajustar hiperparÃ¢metros (GridSearch, Optuna, Bayesian Search, Random Search, Optuna / Hyperopt).
- Tracking de experimentos (MLflow, Weights & Biases).
- ReduÃ§Ã£o de overfitting com regularizaÃ§Ã£o e dropout.

### 6ï¸âƒ£ ValidaÃ§Ã£o e MÃ©tricas
#### 6.1 MÃ©tricas de exemplo:
- ClassificaÃ§Ã£o: AUC, F1-Score, Precision, Recall
- RegressÃ£o: RMSE, MAE, RÂ²
- SÃ©ries temporais: MAPE, SMAPE
- Clustering: Silhouette Score
#### 6.2. AvaliaÃ§Ãµes adicionais:
- Curvas ROC e PR
- Matriz de confusÃ£o
- ImportÃ¢ncia das variÃ¡veis
- Testes de estabilidade (drift)
#### 6.3. Testes adicionais:
- ValidaÃ§Ã£o cruzada.
- Teste A/B.
- Checagem de viÃ©s (fairness).
- Overfitting/underfitting.

### 7ï¸âƒ£ Deploy do Modelo
#### Formas de deploy:
- API REST (FastAPI, Flask)
- Pipeline em nuvem (AWS Lambda, GCP Cloud Run, Azure ML)
- Deploy em batch (execuÃ§Ã£o programada)
- Deploy embarcado (apps, dispositivos)

### 8ï¸âƒ£ Monitoramento e ManutenÃ§Ã£o
#### Itens monitorados:
- Data drift (mudanÃ§a nos dados)
- Concept drift (mudanÃ§a nos padrÃµes)
- LatÃªncia
- Custo de infraestrutura
- Acertos vs. erros ao longo do tempo
#### AÃ§Ãµes:
- Retreinar o modelo
- Ajustar pipelines de ETL
- Revisar features
- Rodar auditoria de fairness / bias
